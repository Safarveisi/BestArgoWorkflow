apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: k8s-orchestrate-
  namespace: playground
spec:
  serviceAccountName: playground-sa
  entrypoint: k8s-orchestrate
  templates:
  - name: k8s-orchestrate
    steps:

    - - name: random-number-job
        template: random-number-job

    - - name: print-generated-numbers
        template: print-generated-numbers
        arguments:
          parameters:
          - name: job-uid
            value: '{{steps.random-number-job.outputs.parameters.job-uid}}'

    - - name: delete-job
        template: delete-job
        arguments:
          parameters:
          - name: job-name
            value: '{{steps.random-number-job.outputs.parameters.job-name}}'
    
    - - name: spark-application
        template: spark-application
    
    - - name: delete-spark-application
        template: delete-spark-application
        arguments:
          parameters:
            - name: spark-application-name
              value: '{{steps.spark-application.outputs.parameters.spark-application-name}}' 

  - name: spark-application
    resource:
      action: create
      successCondition: status.applicationState.state == COMPLETED
      failureCondition: status.applicationState.state == FAILED
      manifest: |
        apiVersion: sparkoperator.k8s.io/v1beta2
        kind: SparkApplication
        metadata:
          name: spark-pi-python
          namespace: {{workflow.namespace}}
        spec:
          type: Python
          pythonVersion: "3"
          mode: cluster
          image: docker.io/ciaa/spark-jobs:v0.1.0
          imagePullPolicy: IfNotPresent
          mainApplicationFile: local:///opt/spark/examples/src/main/python/spark-job.py
          sparkVersion: 4.0.0
          driver:
            cores: 1
            memory: 512m
            serviceAccount: spark-operator-spark
            securityContext:
              capabilities:
                drop:
                - ALL
              runAsGroup: 185
              runAsUser: 185
              runAsNonRoot: true
              allowPrivilegeEscalation: false
              seccompProfile:
                type: RuntimeDefault
          executor:
            instances: 1
            cores: 1
            memory: 512m
            securityContext:
              capabilities:
                drop:
                - ALL
              runAsGroup: 185
              runAsUser: 185
              runAsNonRoot: true
              allowPrivilegeEscalation: false
              seccompProfile:
                type: RuntimeDefault
    outputs:
      parameters:
      - name: spark-application-name
        valueFrom:
          jsonPath: '{.metadata.name}'

  - name: random-number-job
    resource:
      action: create
      successCondition: status.succeeded > 9
      failureCondition: status.failed > 0
      manifest: |
        apiVersion: batch/v1
        kind: Job
        metadata:
          generateName: rand-num-
          namespace: {{workflow.namespace}}
        spec:
          completions: 10
          parallelism: 10
          template:
            metadata:
              name: rand
            spec:
              containers:
              - name: rand
                image: python:alpine3.6
                command: ["python", "-c", "import random; import time; print(random.randint(1, 1000)); time.sleep(10)"]
              restartPolicy: Never
    outputs:
      parameters:
      - name: job-name
        valueFrom:
          jsonPath: '{.metadata.name}'
      - name: job-uid
        valueFrom:
          jsonPath: '{.metadata.uid}'

  - name: print-generated-numbers
    inputs:
      parameters:
      - name: job-uid
    container:
      image: bitnami/kubectl:latest
      command: [sh, -c]
      args:
        - | 
          for pod in $(kubectl get pods -n {{workflow.namespace}} \
                     -l controller-uid={{inputs.parameters.job-uid}} \
                     -o name); do
            kubectl logs -n {{workflow.namespace}} "$pod"
          done

  - name: delete-job
    inputs:
      parameters:
      - name: job-name
    resource:
      action: delete
      manifest: |
        apiVersion: batch/v1
        kind: Job
        metadata:
          name: {{inputs.parameters.job-name}}
          namespace: {{workflow.namespace}}
  
  - name: delete-spark-application
    inputs:
      parameters:
        - name: spark-application-name
    resource:
      action: delete
      manifest: |
        apiVersion: sparkoperator.k8s.io/v1beta2
        kind: SparkApplication
        metadata:
          name: {{inputs.parameters.spark-application-name}}
          namespace: {{workflow.namespace}}